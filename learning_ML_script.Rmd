---
title: "Intro to Machine Learning"
author: "Sophie Breitbart"
date: "7/23/2022"
output:
  html_document:
    toc: true
    theme: united
    depth: 3
    highlight: tango
---

# Tutorial 1: The k-nearest neighbours algorithm (K-nn)

Source: <https://ourcodingclub.github.io/tutorials/machine-learning/>

This tutorial covers the following:

- the very basics of machine learning in R
- implementing a k-nearest neighbour classification algorithm
- building our own training and test datasets
- testing and evaluating our knn algorithm using cross-tabulation

> "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E."

In simple terms, machine Learning is the science of developing and making use of specialised statistical learning algorithms that produce a predictive model based on information gathered from input data.

| **Unsupervised learning**                                                                                                      | **Supervised learning**                                                                  |
|--------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------|
|  Inferring a function that describes the structure of "unlabeled" data (i.e. data that has not been classified or categorized).| Learning a function that maps an input to an output based on example input-output pairs. |

-   This tutorial's focus, the k-nearest neighbors algorithm (K-nn), is a type of supervised learning.

How this works:

1.  You already have a dataset with multiple classes, each associated with points.
2.  You introduce a new, unclassified point to the dataset.
3.  You choose a number for k
4.  The algorithm finds the nearest k neighbors to the unclassified point.
5.  The algorithm measures the distance from the nearest k neighbors to the unclassified point.
6.  The algorithm ranks those distances and assigns a value to the previously unclassified point based on which group's distances were closest to that point.

## Set up notebook
### Load libraries and data
```{r message=FALSE, warning=FALSE}
# Loading required packages for this tutorial
library(ggplot2)
library(dplyr)
library(class)
library(gridExtra)
# install.packages("gmodels")
library(gmodels)
library(magrittr)

# Load iris dataset, then view structure
iris.data <- iris %T>%
  str()
```

## Visualize data
```{r}
# Scatter plot visualising petal width and length grouped by species
(scatter <- ggplot(iris.data,
                  aes(x = Petal.Width,
                      y = Petal.Length,
                      color = Species)) +
  geom_point(size = 3, alpha = 0.6) +
  theme_classic() +
  theme(legend.position = c(0.2, 0.8)) )


# Boxplot visualising variation in petal width between species
(boxplot <- ggplot(iris.data,
                  aes(x = Species,
                      y = Petal.Width,
                      fill = Species)) +
  geom_violin() +
  geom_jitter(color = "black") +
  theme_classic() +
  theme(legend.position = c(0.2, 0.8)))


```

## Train algorithm

> Overarching question: Can we predict what species iris plants belong to based on structural trait data alone?

The **goal of this tutorial** will be to answer this question by **building a predictive model and assessing its performance.**

To do so, we will:

-   take a random sample of our data --\> use as training data
-   take another sample --\> use to test our model

Then, compare these final predictions to our original data to assess our results and gauge model accuracy.

### Normalize data
The scales of individual variables may vary with a given dataset. For example one variable may have values ranging from 0 - 1 while the other ranges from 0 - 1000. Therefore some scaling/normalisation is often useful, espescially with the knn algorithm which is quite sensitive to different intervals across variables given that it employs a distance function when searching for ‘nearest-neighbours’.

```{r}
# Build a normalisation function
normalise <- function(x) {
  num <- x - min(x)
  denom <- max(x) - min(x)
  return (num/denom)
}

# normalize dataset
iris.norm <- as.data.frame(lapply(iris[1:4], normalise))
```

### Generate training data
```{r}
# Randomly generate our training and test samples and their respective labels/classes

# the 'sample' function generates a random sample of the specified size from the data set or elements.
# Also note that we also use the set.seed function to ensure that we always generate the same random data sample

set.seed(1234)

# Randomly generating our training and test samples with a respective ratio of 2/3 and 1/3
# Selects 1/3 rows to be in test sample (2), 2/3 rows to be in training sample (1)
datasample <- sample(2,
                     nrow(iris.norm),
                     replace = TRUE, 
                     prob = c(0.67, 0.33))

# Generate training set
iris.training <- iris.norm %>%
  dplyr::filter(datasample == 1)

# Generate test set 
iris.test <- iris.norm %>%
  dplyr::filter(datasample == 2)

# Generate training labels
irisTraining.labels <- iris[datasample == 1, 5]

# Generate test labels
irisTest.labels <- iris[datasample == 2, 5]
```

### Build k-nn classifier
Use the `knn()` function from the `class` package. We will pass the function the following parameters:

- normalised training dataset
- normalised test dataset
- original training labels
- value for K (in this case, 3)
  - By choosing an odd value, we avoid a tie between the two classes during the algorithm’s majority voting process.

```{r}
iris.knn <- knn(train = iris.training,
                test = iris.test, 
                cl = irisTraining.labels, 
                k = 3)
```

## Assess model performance
To do this, we want to find out if the classes our algorithm predicts based on the training data accurately predicted the species classes in our original iris dataset. For this we compare the original class labels to the predictions made by our algorithm.

```{r}
# creating a dataframe from known (true) test labels
test.labels <- data.frame(irisTest.labels)

# combining predicted and known species classes
class.comparison <- data.frame(iris.knn, test.labels)

# giving appropriate column names
names(class.comparison) <- c("Predicted Species", 
                             "Observed Species")

# inspect the class.comparison table to see if our predicted species align with our observed species
class.comparison
```

Create a cross-table, aka contingency table, to understand which correlations exist between different categorical variables.

In this case we will be able to tell what classes our model predicted and how those predicted classes compare to the actual iris classes.

```{r}
CrossTable(x = irisTest.labels,
           y = iris.knn, 
           prop.chisq = FALSE)
```

We can see that it incorrectly assigned 2 virginiaca points as versicolor.

To improve the model, I could now experiment with using different k values to see if this impacts the model results in any way.

## Create new model, then assess performance & compare

```{r}
# change k from 3 to 5
iris.knn2 <- knn(train = iris.training,
                test = iris.test, 
                cl = irisTraining.labels, 
                k = 5)
```

```{r}
# combining predicted and known species classes
class.comparison2 <- data.frame(iris.knn2,
                                test.labels)

# giving appropriate column names
names(class.comparison2) <- c("Predicted Species", 
                             "Observed Species")

# inspect the class.comparison table to see if our predicted species align with our observed species
class.comparison2

# look at contingency table
CrossTable(x = irisTest.labels,
           y = iris.knn2, 
           prop.chisq = FALSE)
```

Same results as model using k = 3!